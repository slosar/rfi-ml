{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a8GB6oVO84bB"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.8.1 torchvision==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ChVQY4TY88_S"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wlq-QYvS89VZ",
    "outputId": "d91ff960-fd28-4dec-86ac-fdf947de2513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ebd9e035d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "torch.cuda.is_available()\n",
    "np.random.seed(0) #for debugging\n",
    "torch.manual_seed(0) #more debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tifsHjrZ8_q2"
   },
   "outputs": [],
   "source": [
    "def getGaussian(Nfft, Pk):\n",
    "    xf = np.random.normal(0,1,Nfft)+1j*np.random.normal(0,1,Nfft)\n",
    "    xf *= Pk\n",
    "    return np.fft.irfft(xf)\n",
    "\n",
    "def getNonGaussian(t):\n",
    "    # Signal with non-Gaussian shape\n",
    "    freq = np.random.uniform(200,500)\n",
    "    phase = np.random.uniform(0,2*np.pi)\n",
    "    sigma = 0.03\n",
    "    pos = np.random.uniform(3*sigma,1-3*sigma)\n",
    "    ampl = np.random.uniform (0.1,0.2)\n",
    "    rfi = ampl*np.cos(phase+freq*t)*np.exp(-(t-pos)**2/(2*sigma**2))\n",
    "    #print('freq: ', freq)\n",
    "    #print('phase: ', phase)\n",
    "    #print('pos: ', pos)\n",
    "    #print('ampl: ',ampl)\n",
    "    return rfi\n",
    "\n",
    "def Gaussianize(signal):\n",
    "    fsig = np.fft.rfft(signal)\n",
    "    rot = np.exp(1j*np.random.uniform(0,2*np.pi,len(fsig)))\n",
    "    return np.fft.irfft((fsig*rot))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vlV5_cSX9Oh-"
   },
   "outputs": [],
   "source": [
    "# define the network classes\n",
    "# the decoder network\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, z_dim, hidden_dim, out_dim):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Linear(z_dim, hidden_dim),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "\n",
    "      nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "\n",
    "      nn.Linear(hidden_dim * 2, out_dim, bias=False),\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.main(x)\n",
    "    return out\n",
    "    #return x-self.main(x)\n",
    "\n",
    "\n",
    "\n",
    "# the encoder network\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim * 2),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "      nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "      nn.Dropout(0.2),\n",
    "      nn.Linear(hidden_dim, z_dim)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.main(x)\n",
    "    return out\n",
    "    #return x-self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fb_NtjP9QW7",
    "outputId": "481e3634-2da6-4eb4-cbda-3bc410a71511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/3][  0/3125]\tLoss: 0.0020396314\n",
      "[  0/3][100/3125]\tLoss: 0.0012840308\n",
      "[  0/3][200/3125]\tLoss: 0.0014177836\n",
      "[  0/3][300/3125]\tLoss: 0.0012635158\n",
      "[  0/3][400/3125]\tLoss: 0.0013053633\n",
      "[  0/3][500/3125]\tLoss: 0.0012558863\n",
      "[  0/3][600/3125]\tLoss: 0.0012637856\n",
      "[  0/3][700/3125]\tLoss: 0.0012630094\n",
      "[  0/3][800/3125]\tLoss: 0.0012273312\n",
      "[  0/3][900/3125]\tLoss: 0.0012013507\n",
      "[  0/3][1000/3125]\tLoss: 0.0012612687\n",
      "[  0/3][1100/3125]\tLoss: 0.0012096667\n",
      "[  0/3][1200/3125]\tLoss: 0.0012510667\n",
      "[  0/3][1300/3125]\tLoss: 0.0012700292\n",
      "[  0/3][1400/3125]\tLoss: 0.0012602669\n",
      "[  0/3][1500/3125]\tLoss: 0.0012575523\n",
      "[  0/3][1600/3125]\tLoss: 0.0012189510\n",
      "[  0/3][1700/3125]\tLoss: 0.0012320076\n",
      "[  0/3][1800/3125]\tLoss: 0.0012188797\n",
      "[  0/3][1900/3125]\tLoss: 0.0012423766\n",
      "[  0/3][2000/3125]\tLoss: 0.0012400369\n",
      "[  0/3][2100/3125]\tLoss: 0.0012350675\n",
      "[  0/3][2200/3125]\tLoss: 0.0012383685\n",
      "[  0/3][2300/3125]\tLoss: 0.0011585031\n",
      "[  0/3][2400/3125]\tLoss: 0.0012328201\n",
      "[  0/3][2500/3125]\tLoss: 0.0011732216\n",
      "[  0/3][2600/3125]\tLoss: 0.0011315236\n",
      "[  0/3][2700/3125]\tLoss: 0.0011856611\n",
      "[  0/3][2800/3125]\tLoss: 0.0011377442\n",
      "[  0/3][2900/3125]\tLoss: 0.0011426918\n",
      "[  0/3][3000/3125]\tLoss: 0.0011912151\n",
      "[  0/3][3100/3125]\tLoss: 0.0012245288\n",
      "[  1/3][ 75/3125]\tLoss: 0.0011768313\n",
      "[  1/3][175/3125]\tLoss: 0.0011602413\n",
      "[  1/3][275/3125]\tLoss: 0.0011821508\n",
      "[  1/3][375/3125]\tLoss: 0.0012285025\n",
      "[  1/3][475/3125]\tLoss: 0.0012444624\n",
      "[  1/3][575/3125]\tLoss: 0.0011704046\n",
      "[  1/3][675/3125]\tLoss: 0.0011877898\n",
      "[  1/3][775/3125]\tLoss: 0.0012039325\n",
      "[  1/3][875/3125]\tLoss: 0.0012060292\n",
      "[  1/3][975/3125]\tLoss: 0.0011820325\n",
      "[  1/3][1075/3125]\tLoss: 0.0011536245\n",
      "[  1/3][1175/3125]\tLoss: 0.0011561104\n",
      "[  1/3][1275/3125]\tLoss: 0.0011310289\n",
      "[  1/3][1375/3125]\tLoss: 0.0011387304\n",
      "[  1/3][1475/3125]\tLoss: 0.0011357022\n",
      "[  1/3][1575/3125]\tLoss: 0.0012061683\n",
      "[  1/3][1675/3125]\tLoss: 0.0011132144\n",
      "[  1/3][1775/3125]\tLoss: 0.0011509818\n",
      "[  1/3][1875/3125]\tLoss: 0.0011255244\n",
      "[  1/3][1975/3125]\tLoss: 0.0010931098\n",
      "[  1/3][2075/3125]\tLoss: 0.0011583176\n",
      "[  1/3][2175/3125]\tLoss: 0.0011855511\n",
      "[  1/3][2275/3125]\tLoss: 0.0011424080\n",
      "[  1/3][2375/3125]\tLoss: 0.0011306830\n",
      "[  1/3][2475/3125]\tLoss: 0.0011248355\n",
      "[  1/3][2575/3125]\tLoss: 0.0010989865\n",
      "[  1/3][2675/3125]\tLoss: 0.0011789965\n",
      "[  1/3][2775/3125]\tLoss: 0.0010826271\n",
      "[  1/3][2875/3125]\tLoss: 0.0011399153\n",
      "[  1/3][2975/3125]\tLoss: 0.0010849561\n",
      "[  1/3][3075/3125]\tLoss: 0.0010343050\n",
      "[  2/3][ 50/3125]\tLoss: 0.0010963379\n",
      "[  2/3][150/3125]\tLoss: 0.0010747345\n",
      "[  2/3][250/3125]\tLoss: 0.0010914908\n",
      "[  2/3][350/3125]\tLoss: 0.0010925565\n",
      "[  2/3][450/3125]\tLoss: 0.0011232948\n",
      "[  2/3][550/3125]\tLoss: 0.0010879842\n",
      "[  2/3][650/3125]\tLoss: 0.0011373780\n",
      "[  2/3][750/3125]\tLoss: 0.0010431621\n",
      "[  2/3][850/3125]\tLoss: 0.0011245240\n",
      "[  2/3][950/3125]\tLoss: 0.0011242356\n",
      "[  2/3][1050/3125]\tLoss: 0.0011292214\n",
      "[  2/3][1150/3125]\tLoss: 0.0010654472\n",
      "[  2/3][1250/3125]\tLoss: 0.0009868932\n",
      "[  2/3][1350/3125]\tLoss: 0.0010551963\n",
      "[  2/3][1450/3125]\tLoss: 0.0010738340\n",
      "[  2/3][1550/3125]\tLoss: 0.0010695013\n",
      "[  2/3][1650/3125]\tLoss: 0.0010436347\n",
      "[  2/3][1750/3125]\tLoss: 0.0010736557\n",
      "[  2/3][1850/3125]\tLoss: 0.0009988945\n",
      "[  2/3][1950/3125]\tLoss: 0.0011999421\n",
      "[  2/3][2050/3125]\tLoss: 0.0009367977\n",
      "[  2/3][2150/3125]\tLoss: 0.0010317557\n",
      "[  2/3][2250/3125]\tLoss: 0.0010019501\n",
      "[  2/3][2350/3125]\tLoss: 0.0010349498\n",
      "[  2/3][2450/3125]\tLoss: 0.0009482444\n",
      "[  2/3][2550/3125]\tLoss: 0.0010224844\n",
      "[  2/3][2650/3125]\tLoss: 0.0010500844\n",
      "[  2/3][2750/3125]\tLoss: 0.0009765102\n",
      "[  2/3][2850/3125]\tLoss: 0.0010621733\n",
      "[  2/3][2950/3125]\tLoss: 0.0010490902\n",
      "[  2/3][3050/3125]\tLoss: 0.0009643131\n",
      "Saving file...ae-g/2021-06-14_17-41-39_epoch_0000002_test_0.png\n",
      "Saving file...ae-g/2021-06-14_17-41-39_overplot_test_0.png\n",
      "Saving file...ae-g/2021-06-14_17-41-40_epoch_0000002_test_1.png\n",
      "Saving file...ae-g/2021-06-14_17-41-40_overplot_test_1.png\n",
      "Saving file...ae-g/2021-06-14_17-41-41_epoch_0000002_test_2.png\n",
      "Saving file...ae-g/2021-06-14_17-41-41_overplot_test_2.png\n",
      "Saving file...ae-g/2021-06-14_17-41-41_epoch_0000002_test_3.png\n",
      "Saving file...ae-g/2021-06-14_17-41-41_overplot_test_3.png\n",
      "Saving file...ae-g/2021-06-14_17-41-42_epoch_0000002_test_4.png\n",
      "Saving file...ae-g/2021-06-14_17-41-42_overplot_test_4.png\n",
      "Saving file...ae-g/2021-06-14_17-41-43_epoch_0000002_test_5.png\n",
      "Saving file...ae-g/2021-06-14_17-41-43_overplot_test_5.png\n",
      "Saving file...ae-g/2021-06-14_17-41-44_epoch_0000002_test_6.png\n",
      "Saving file...ae-g/2021-06-14_17-41-44_overplot_test_6.png\n",
      "Saving file...ae-g/2021-06-14_17-41-45_epoch_0000002_test_7.png\n",
      "Saving file...ae-g/2021-06-14_17-41-45_overplot_test_7.png\n",
      "Saving file...ae-g/2021-06-14_17-41-45_epoch_0000002_test_8.png\n",
      "Saving file...ae-g/2021-06-14_17-41-45_overplot_test_8.png\n",
      "Saving file...ae-g/2021-06-14_17-41-46_epoch_0000002_test_9.png\n",
      "Saving file...ae-g/2021-06-14_17-41-46_overplot_test_9.png\n",
      "Numpy rand int check:  [0.22745992]\n",
      "Torch rand int check:  tensor([0.5666])\n"
     ]
    }
   ],
   "source": [
    "# training constants\n",
    "BATCH_SIZE = 32\n",
    "Z_DIM = 16\n",
    "HIDDEN_DIM = 256\n",
    "LR = 0.0002\n",
    "EPOCHS = 3\n",
    "NCORES = 4\n",
    "NTRAINING = 100000\n",
    "NTEST = 10\n",
    "\n",
    "# data parameters\n",
    "N = 1024\n",
    "Nfft = N//2+1\n",
    "k = np.linspace(0,1,Nfft)\n",
    "t = np.linspace(0,1,N)\n",
    "Pk = (1+np.exp(-(k-0.5)**2/(2*0.1**2)))*np.exp(-k/0.5) #spectrum of noise\n",
    "\n",
    "g = torch.stack([torch.from_numpy(getGaussian(Nfft, Pk)) for i in range(NTRAINING+NTEST)])\n",
    "ng = torch.stack([torch.from_numpy(getNonGaussian(t)) for i in range(NTRAINING+NTEST)])\n",
    "\n",
    "# train data\n",
    "g_train_array = g[:NTRAINING]\n",
    "ng_train_array = ng[:NTRAINING]\n",
    "\n",
    "# test data\n",
    "g_test_array = g[NTRAINING:]\n",
    "ng_test_array = ng[NTRAINING:]\n",
    "\n",
    "# create dataloaders\n",
    "g_trainloader = DataLoader(\n",
    "      torch.utils.data.TensorDataset(g_train_array),\n",
    "      batch_size=BATCH_SIZE, shuffle=True, num_workers=NCORES, pin_memory=True, drop_last=True\n",
    ")\n",
    "ng_trainloader = DataLoader(\n",
    "      torch.utils.data.TensorDataset(ng_train_array),\n",
    "      batch_size=BATCH_SIZE, shuffle=True, num_workers=NCORES, pin_memory=True, drop_last=True\n",
    ")\n",
    "\n",
    "# initialize the networks\n",
    "netD = Decoder(z_dim=Z_DIM, hidden_dim=HIDDEN_DIM, out_dim=N).cuda()\n",
    "netE = Encoder(input_dim=N, hidden_dim=HIDDEN_DIM, z_dim=Z_DIM).cuda()\n",
    "\n",
    "# define the optimizers\n",
    "optimizer = optim.Adam([{'params': netE.parameters()}, \n",
    "                        {'params': netD.parameters()}], lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# loss criterion\n",
    "recons_criterion = nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # iterate through the dataloaders\n",
    "  for i, (g, ng) in enumerate(zip(g_trainloader, ng_trainloader)):\n",
    "      # set to train mode\n",
    "      netE.train()\n",
    "      netD.train()\n",
    "      \n",
    "      ng = ng[0].float().cuda()\n",
    "      g = g[0].float().cuda()\n",
    "      #bs = ng.shape[0]\n",
    "\n",
    "      # new inputs\n",
    "      sigs = g + ng\n",
    "      gaussianized = torch.stack([torch.from_numpy(Gaussianize(sig.cpu().numpy())) for sig in sigs]).cuda().float()\n",
    "      modsig = sigs + gaussianized\n",
    "      \n",
    "      # for the noisy input get latent representation from the encoder\n",
    "      z_out = netE(modsig)\n",
    "\n",
    "      # decode the latent representation\n",
    "      recons_out = netD(z_out)\n",
    "\n",
    "      # compute the loss\n",
    "      #loss = recons_criterion(recons_out, ng)\n",
    "    \n",
    "      loss = recons_criterion(modsig-recons_out, gaussianized)\n",
    "\n",
    "      # backpropagate and update the weights\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # print the training losses\n",
    "      if iters % 100 == 0:\n",
    "        print('[%3d/%d][%3d/%d]\\tLoss: %.10f' \n",
    "            % (epoch, EPOCHS, i, len(g_trainloader), loss.item()))\n",
    "        #print(sigs.grad_fn)\n",
    "        #print(sigs.grad)\n",
    "      iters += 1    \n",
    "  # visualize generated samples\n",
    "  if epoch+1==EPOCHS: ## end of final epoch\n",
    "    # set to eval mode\n",
    "    netD.eval()\n",
    "    netE.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # new inputs\n",
    "      sigs = g_test_array.float().cuda() + ng_test_array.float().cuda()\n",
    "      gaussianized = torch.stack([torch.from_numpy(Gaussianize(sig.cpu().numpy())) for sig in sigs]).cuda()\n",
    "      modsig = (sigs + gaussianized).float()\n",
    "      z_out = netE(modsig)\n",
    "      recons_out = netD(z_out)\n",
    "\n",
    "    # display a random sample from the test set\n",
    "    #rand_int = np.random.randint(10)\n",
    "\n",
    "    for test_int in range(NTEST):\n",
    "        # plot/save generated samples\n",
    "        plt.figure(figsize=(17,10))\n",
    "        ax = plt.subplot(2,3,1)\n",
    "        plt.plot(t, ng_test_array[test_int].cpu().numpy()) # ng\n",
    "        ax.set_title(\"ng\")\n",
    "\n",
    "        ax = plt.subplot(2,3,2)\n",
    "        plt.plot(t, g_test_array[test_int].cpu().numpy()) # g\n",
    "        ax.set_title(\"g\")\n",
    "\n",
    "        ax = plt.subplot(2,3,3)\n",
    "        plt.plot(t, (g_test_array[test_int].cpu() + ng_test_array[test_int].cpu()).numpy()) # g + ng \n",
    "        ax.set_title(\"sig = ng + g\")\n",
    "\n",
    "        ax = plt.subplot(2,3,4)\n",
    "        plt.plot(t, gaussianized[test_int].cpu().numpy()) # gaussianize(ng + g)\n",
    "        ax.set_title(\"Gauss(sig)\")\n",
    "\n",
    "        ax = plt.subplot(2,3,5)\n",
    "        plt.plot(t, modsig[test_int].cpu().numpy()) # input\n",
    "        ax.set_title(\"network input=Gauss(sig) + sig\")\n",
    "\n",
    "        ax = plt.subplot(2,3,6)\n",
    "        plt.plot(t, recons_out[test_int].cpu().detach().numpy()) # output\n",
    "        ax.set_title(\"network output (~ng)\")\n",
    "\n",
    "        save_folder = 'ae-g/'\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        save_time = str(datetime.datetime.now()).split('.')[0].replace(' ','_').replace(':','-')\n",
    "        #save_filename = str(epoch).zfill(7) + '.png'\n",
    "        save_filename = save_time + '_epoch_' + str(epoch).zfill(7) + '_test_' + str(test_int) + '.png'\n",
    "        save_path = os.path.join(save_folder, save_filename)\n",
    "        #save_path = os.path.join(save_folder, str(epoch).zfill(7) + '.png')\n",
    "        print('Saving file...{}'.format(save_path))\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        #Overplot\n",
    "        plt.plot(sigs[test_int].cpu().numpy())\n",
    "        plt.plot(recons_out[test_int].cpu().detach().numpy())\n",
    "        plt.plot(ng_test_array[test_int].cpu().numpy())\n",
    "        plt.legend(['Test In','Recovered','RFI'])\n",
    "    \n",
    "        save_filename = save_time + '_overplot_test_' + str(test_int) + '.png'\n",
    "        save_path = os.path.join(save_folder, save_filename)\n",
    "        print('Saving file...{}'.format(save_path))\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    #rand int seed check\n",
    "    print('Numpy rand int check: ',np.random.uniform(0,1,1))\n",
    "    print('Torch rand int check: ',torch.rand(1))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "7sZh2DLJGOFS",
    "outputId": "63162750-655b-439e-d109-3b3cbd176af8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-57d13c8d900c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#!zip -r /content/file.zip /content/ae-g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zip -r file.zip /content/ae-g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#files.download(\"/content/file.zip\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "#!zip -r /content/file.zip /content/ae-g\n",
    "!zip -r file.zip /content/ae-g\n",
    "#files.download(\"/content/file.zip\")\n",
    "files.download(\"file.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ae-g.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
