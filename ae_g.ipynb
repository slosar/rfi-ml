{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a8GB6oVO84bB"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.8.1 torchvision==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ChVQY4TY88_S"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wlq-QYvS89VZ",
    "outputId": "d91ff960-fd28-4dec-86ac-fdf947de2513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tifsHjrZ8_q2"
   },
   "outputs": [],
   "source": [
    "def getGaussian(Nfft, Pk):\n",
    "    xf = np.random.normal(0,1,Nfft)+1j*np.random.normal(0,1,Nfft)\n",
    "    xf *= Pk\n",
    "    return np.fft.irfft(xf)\n",
    "\n",
    "def getNonGaussian(t):\n",
    "    # Signal with non-Gaussian shape\n",
    "    freq = np.random.uniform(200,500)\n",
    "    phase = np.random.uniform(0,2*np.pi)\n",
    "    sigma = 0.03\n",
    "    pos = np.random.uniform(3*sigma,1-3*sigma)\n",
    "    ampl = np.random.uniform (0.1,0.2)\n",
    "    rfi = ampl*np.cos(phase+freq*t)*np.exp(-(t-pos)**2/(2*sigma**2))\n",
    "    return rfi\n",
    "\n",
    "def Gaussianize(signal):\n",
    "    fsig = np.fft.rfft(signal)\n",
    "    rot = np.exp(1j*np.random.uniform(0,2*np.pi,len(fsig)))\n",
    "    return np.fft.irfft((fsig*rot))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vlV5_cSX9Oh-"
   },
   "outputs": [],
   "source": [
    "# define the network classes\n",
    "# the decoder network\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, z_dim, hidden_dim, out_dim):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Linear(z_dim, hidden_dim),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "\n",
    "      nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "\n",
    "      nn.Linear(hidden_dim * 2, out_dim, bias=False),\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.main(x)\n",
    "    return out\n",
    "    #return x-self.main(x)\n",
    "\n",
    "\n",
    "\n",
    "# the encoder network\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim * 2),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "\n",
    "      nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "      nn.LeakyReLU(0.02, inplace=False),\n",
    "      nn.Dropout(0.2),\n",
    "\n",
    "      nn.Linear(hidden_dim, z_dim)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.main(x)\n",
    "    return out\n",
    "    #return x-self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fb_NtjP9QW7",
    "outputId": "481e3634-2da6-4eb4-cbda-3bc410a71511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/3][  0/3125]\tLoss: 0.0021073672\n",
      "[  0/3][100/3125]\tLoss: 0.0013130317\n",
      "[  0/3][200/3125]\tLoss: 0.0012917498\n",
      "[  0/3][300/3125]\tLoss: 0.0012405853\n",
      "[  0/3][400/3125]\tLoss: 0.0012889009\n",
      "[  0/3][500/3125]\tLoss: 0.0012338536\n",
      "[  0/3][600/3125]\tLoss: 0.0012624802\n",
      "[  0/3][700/3125]\tLoss: 0.0012653806\n",
      "[  0/3][800/3125]\tLoss: 0.0013344057\n",
      "[  0/3][900/3125]\tLoss: 0.0012073349\n",
      "[  0/3][1000/3125]\tLoss: 0.0011862975\n",
      "[  0/3][1100/3125]\tLoss: 0.0012908929\n",
      "[  0/3][1200/3125]\tLoss: 0.0012190664\n",
      "[  0/3][1300/3125]\tLoss: 0.0012574324\n",
      "[  0/3][1400/3125]\tLoss: 0.0011578375\n",
      "[  0/3][1500/3125]\tLoss: 0.0012172877\n",
      "[  0/3][1600/3125]\tLoss: 0.0011953666\n",
      "[  0/3][1700/3125]\tLoss: 0.0011909356\n",
      "[  0/3][1800/3125]\tLoss: 0.0012198958\n",
      "[  0/3][1900/3125]\tLoss: 0.0012633000\n",
      "[  0/3][2000/3125]\tLoss: 0.0011285461\n",
      "[  0/3][2100/3125]\tLoss: 0.0012379328\n",
      "[  0/3][2200/3125]\tLoss: 0.0012443028\n",
      "[  0/3][2300/3125]\tLoss: 0.0011847841\n",
      "[  0/3][2400/3125]\tLoss: 0.0012259242\n",
      "[  0/3][2500/3125]\tLoss: 0.0012129752\n",
      "[  0/3][2600/3125]\tLoss: 0.0011825137\n",
      "[  0/3][2700/3125]\tLoss: 0.0012589837\n",
      "[  0/3][2800/3125]\tLoss: 0.0012338175\n",
      "[  0/3][2900/3125]\tLoss: 0.0012226771\n",
      "[  0/3][3000/3125]\tLoss: 0.0012051375\n",
      "[  0/3][3100/3125]\tLoss: 0.0013089408\n",
      "Saving file...ae-g/0000000.png\n",
      "[  1/3][ 75/3125]\tLoss: 0.0012164585\n",
      "[  1/3][175/3125]\tLoss: 0.0012180968\n",
      "[  1/3][275/3125]\tLoss: 0.0012026068\n",
      "[  1/3][375/3125]\tLoss: 0.0012852668\n",
      "[  1/3][475/3125]\tLoss: 0.0011789503\n",
      "[  1/3][575/3125]\tLoss: 0.0011515949\n",
      "[  1/3][675/3125]\tLoss: 0.0011886845\n",
      "[  1/3][775/3125]\tLoss: 0.0011241009\n",
      "[  1/3][875/3125]\tLoss: 0.0011509913\n",
      "[  1/3][975/3125]\tLoss: 0.0012275057\n",
      "[  1/3][1075/3125]\tLoss: 0.0010964301\n",
      "[  1/3][1175/3125]\tLoss: 0.0012119962\n",
      "[  1/3][1275/3125]\tLoss: 0.0011637683\n",
      "[  1/3][1375/3125]\tLoss: 0.0011901117\n",
      "[  1/3][1475/3125]\tLoss: 0.0010967674\n",
      "[  1/3][1575/3125]\tLoss: 0.0011633278\n",
      "[  1/3][1675/3125]\tLoss: 0.0011088192\n",
      "[  1/3][1775/3125]\tLoss: 0.0011025958\n",
      "[  1/3][1875/3125]\tLoss: 0.0011209118\n",
      "[  1/3][1975/3125]\tLoss: 0.0010355070\n",
      "[  1/3][2075/3125]\tLoss: 0.0011581250\n",
      "[  1/3][2175/3125]\tLoss: 0.0011733803\n",
      "[  1/3][2275/3125]\tLoss: 0.0011357830\n",
      "[  1/3][2375/3125]\tLoss: 0.0011605609\n",
      "[  1/3][2475/3125]\tLoss: 0.0010753488\n",
      "[  1/3][2575/3125]\tLoss: 0.0011166066\n",
      "[  1/3][2675/3125]\tLoss: 0.0011062245\n",
      "[  1/3][2775/3125]\tLoss: 0.0011870963\n",
      "[  1/3][2875/3125]\tLoss: 0.0010646950\n",
      "[  1/3][2975/3125]\tLoss: 0.0010043378\n",
      "[  1/3][3075/3125]\tLoss: 0.0011763428\n",
      "Saving file...ae-g/0000001.png\n",
      "[  2/3][ 50/3125]\tLoss: 0.0010395942\n",
      "[  2/3][150/3125]\tLoss: 0.0010828859\n",
      "[  2/3][250/3125]\tLoss: 0.0010573888\n",
      "[  2/3][350/3125]\tLoss: 0.0011033429\n",
      "[  2/3][450/3125]\tLoss: 0.0011103926\n",
      "[  2/3][550/3125]\tLoss: 0.0010532318\n",
      "[  2/3][650/3125]\tLoss: 0.0009972722\n",
      "[  2/3][750/3125]\tLoss: 0.0011154360\n",
      "[  2/3][850/3125]\tLoss: 0.0010722785\n",
      "[  2/3][950/3125]\tLoss: 0.0011399630\n",
      "[  2/3][1050/3125]\tLoss: 0.0010515463\n",
      "[  2/3][1150/3125]\tLoss: 0.0010883100\n",
      "[  2/3][1250/3125]\tLoss: 0.0010021742\n",
      "[  2/3][1350/3125]\tLoss: 0.0010667348\n",
      "[  2/3][1450/3125]\tLoss: 0.0010407309\n",
      "[  2/3][1550/3125]\tLoss: 0.0010395211\n",
      "[  2/3][1650/3125]\tLoss: 0.0009888229\n",
      "[  2/3][1750/3125]\tLoss: 0.0010352706\n",
      "[  2/3][1850/3125]\tLoss: 0.0010189321\n",
      "[  2/3][1950/3125]\tLoss: 0.0010160591\n",
      "[  2/3][2050/3125]\tLoss: 0.0010132494\n",
      "[  2/3][2150/3125]\tLoss: 0.0010291575\n",
      "[  2/3][2250/3125]\tLoss: 0.0010800692\n",
      "[  2/3][2350/3125]\tLoss: 0.0010327875\n",
      "[  2/3][2450/3125]\tLoss: 0.0010184078\n",
      "[  2/3][2550/3125]\tLoss: 0.0009567966\n",
      "[  2/3][2650/3125]\tLoss: 0.0010673160\n",
      "[  2/3][2750/3125]\tLoss: 0.0009973793\n",
      "[  2/3][2850/3125]\tLoss: 0.0010381571\n",
      "[  2/3][2950/3125]\tLoss: 0.0009528905\n",
      "[  2/3][3050/3125]\tLoss: 0.0009833621\n",
      "Saving file...ae-g/0000002.png\n"
     ]
    }
   ],
   "source": [
    "# training constants\n",
    "BATCH_SIZE = 32\n",
    "Z_DIM = 16\n",
    "HIDDEN_DIM = 256\n",
    "LR = 0.0002\n",
    "EPOCHS = 3\n",
    "\n",
    "# data parameters\n",
    "N = 1024\n",
    "Nfft = N//2+1\n",
    "k = np.linspace(0,1,Nfft)\n",
    "t = np.linspace(0,1,N)\n",
    "Pk = (1+np.exp(-(k-0.5)**2/(2*0.1**2)))*np.exp(-k/0.5)\n",
    "\n",
    "# train data\n",
    "g_train_array = torch.stack([torch.from_numpy(getGaussian(Nfft, Pk)) for i in range(100000)])\n",
    "ng_train_array = torch.stack([torch.from_numpy(getNonGaussian(t)) for i in range(100000)])\n",
    "\n",
    "# test data\n",
    "g_test_array = torch.stack([torch.from_numpy(getGaussian(Nfft, Pk)) for i in range(10)])\n",
    "ng_test_array = torch.stack([torch.from_numpy(getNonGaussian(t)) for i in range(10)])\n",
    "\n",
    "# create dataloaders\n",
    "g_trainloader = DataLoader(\n",
    "      torch.utils.data.TensorDataset(g_train_array),\n",
    "      batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True\n",
    ")\n",
    "ng_trainloader = DataLoader(\n",
    "      torch.utils.data.TensorDataset(ng_train_array),\n",
    "      batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True\n",
    ")\n",
    "\n",
    "# initialize the networks\n",
    "netD = Decoder(z_dim=Z_DIM, hidden_dim=HIDDEN_DIM, out_dim=N).cuda()\n",
    "netE = Encoder(input_dim=N, hidden_dim=HIDDEN_DIM, z_dim=Z_DIM).cuda()\n",
    "\n",
    "# define the optimizers\n",
    "optimizer = optim.Adam([{'params': netE.parameters()}, \n",
    "                        {'params': netD.parameters()}], lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# loss criterion\n",
    "recons_criterion = nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # iterate through the dataloaders\n",
    "  for i, (g, ng) in enumerate(zip(g_trainloader, ng_trainloader)):\n",
    "      # set to train mode\n",
    "      netE.train()\n",
    "      netD.train()\n",
    "\n",
    "      \n",
    "      ng = ng[0].float().cuda()\n",
    "      g = g[0].float().cuda()\n",
    "      bs = ng.shape[0]\n",
    "\n",
    "      # new inputs\n",
    "      sigs = g + ng\n",
    "      gaussianized = torch.stack([torch.from_numpy(Gaussianize(sig.cpu().numpy())) for sig in sigs]).cuda().float()\n",
    "      modsig = sigs + gaussianized\n",
    "      \n",
    "      # for the noisy input get latent representation from the encoder\n",
    "      z_out = netE(modsig)\n",
    "\n",
    "      # decode the latent representation\n",
    "      recons_out = netD(z_out)\n",
    "\n",
    "      # compute the loss\n",
    "      #loss = recons_criterion(recons_out, ng)\n",
    "    \n",
    "      loss = recons_criterion(modsig-recons_out, gaussianized)\n",
    "\n",
    "      # backpropagate and update the weights\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # print the training losses\n",
    "      if iters % 100 == 0:\n",
    "        print('[%3d/%d][%3d/%d]\\tLoss: %.10f' \n",
    "            % (epoch, EPOCHS, i, len(g_trainloader), loss.item()))\n",
    "      iters += 1    \n",
    "  # visualize generated samples\n",
    "  if True: ## end of every epoch\n",
    "    # set to eval mode\n",
    "    netD.eval()\n",
    "    netE.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # new inputs\n",
    "      sigs = g_test_array.float().cuda() + ng_test_array.float().cuda()\n",
    "      gaussianized = torch.stack([torch.from_numpy(Gaussianize(sig.cpu().numpy())) for sig in sigs]).cuda()\n",
    "      modsig = (sigs + gaussianized).float()\n",
    "      z_out = netE(modsig)\n",
    "      recons_out = netD(z_out)\n",
    "\n",
    "    # display a random sample from the test set\n",
    "    rand_int = np.random.randint(10)\n",
    "\n",
    "    # plot/save generated samples\n",
    "    plt.figure(figsize=(17,10))\n",
    "    ax = plt.subplot(2,3,1)\n",
    "    plt.plot(t, ng_test_array[rand_int].cpu().numpy()) # ng\n",
    "    ax.set_title(\"ng\")\n",
    "\n",
    "    ax = plt.subplot(2,3,2)\n",
    "    plt.plot(t, g_test_array[rand_int].cpu().numpy()) # g\n",
    "    ax.set_title(\"g\")\n",
    "\n",
    "    ax = plt.subplot(2,3,3)\n",
    "    plt.plot(t, (g_test_array[rand_int].cpu() + ng_test_array[rand_int].cpu()).numpy()) # g + ng \n",
    "    ax.set_title(\"sig = ng + g\")\n",
    "\n",
    "    ax = plt.subplot(2,3,4)\n",
    "    plt.plot(t, gaussianized[rand_int].cpu().numpy()) # gaussianize(ng + g)\n",
    "    ax.set_title(\"Gauss(sig)\")\n",
    "\n",
    "    ax = plt.subplot(2,3,5)\n",
    "    plt.plot(t, modsig[rand_int].cpu().numpy()) # input\n",
    "    ax.set_title(\"network input=Gauss(sig) + sig\")\n",
    "\n",
    "    ax = plt.subplot(2,3,6)\n",
    "    plt.plot(t, recons_out[rand_int].cpu().detach().numpy()) # output\n",
    "    ax.set_title(\"network output (~ng)\")\n",
    "\n",
    "    save_folder = 'ae-g/'\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    save_path = os.path.join(save_folder, str(epoch).zfill(7) + '.png')\n",
    "    print('Saving file...{}'.format(save_path))\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "7sZh2DLJGOFS",
    "outputId": "63162750-655b-439e-d109-3b3cbd176af8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-57d13c8d900c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#!zip -r /content/file.zip /content/ae-g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r file.zip /content/ae-g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#files.download(\"/content/file.zip\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "#!zip -r /content/file.zip /content/ae-g\n",
    "!zip -r file.zip /content/ae-g\n",
    "#files.download(\"/content/file.zip\")\n",
    "files.download(\"file.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ae-g.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
